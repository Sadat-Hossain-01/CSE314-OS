diff --git a/Makefile b/Makefile
index 39a99d7..151b273 100644
--- a/Makefile
+++ b/Makefile
@@ -132,6 +132,7 @@ UPROGS=\
 	$U/_grind\
 	$U/_wc\
 	$U/_zombie\
+	$U/_threads\
 
 fs.img: mkfs/mkfs README $(UPROGS)
 	mkfs/mkfs fs.img README $(UPROGS)
diff --git a/kernel/defs.h b/kernel/defs.h
index a3c962b..d3ebbaf 100644
--- a/kernel/defs.h
+++ b/kernel/defs.h
@@ -106,6 +106,9 @@ void            yield(void);
 int             either_copyout(int user_dst, uint64 dst, void *src, uint64 len);
 int             either_copyin(void *dst, int user_src, uint64 src, uint64 len);
 void            procdump(void);
+int             thread_create(uint64, uint64, uint64);
+int             thread_join(uint64);
+int             thread_exit(uint64);
 
 // swtch.S
 void            swtch(struct context*, struct context*);
@@ -165,6 +168,7 @@ void            uvmfirst(pagetable_t, uchar *, uint);
 uint64          uvmalloc(pagetable_t, uint64, uint64, int);
 uint64          uvmdealloc(pagetable_t, uint64, uint64);
 int             uvmcopy(pagetable_t, pagetable_t, uint64);
+int             uvmmirror(pagetable_t, pagetable_t, uint64);
 void            uvmfree(pagetable_t, uint64);
 void            uvmunmap(pagetable_t, uint64, uint64, int);
 void            uvmclear(pagetable_t, uint64);
@@ -173,6 +177,8 @@ uint64          walkaddr(pagetable_t, uint64);
 int             copyout(pagetable_t, uint64, char *, uint64);
 int             copyin(pagetable_t, char *, uint64, uint64);
 int             copyinstr(pagetable_t, char *, uint64, uint64);
+uint64          uvmallocmirror(pagetable_t, pagetable_t, uint64, uint64);
+uint64          uvmdeallocmirror(pagetable_t, uint64, uint64);
 
 // plic.c
 void            plicinit(void);
diff --git a/kernel/mem.h b/kernel/mem.h
new file mode 100644
index 0000000..7216d7c
--- /dev/null
+++ b/kernel/mem.h
@@ -0,0 +1,5 @@
+struct mem {
+    struct spinlock lock;
+    int ref_count;
+    int is_allocated;
+};
diff --git a/kernel/proc.c b/kernel/proc.c
index 959b778..b8947b6 100644
--- a/kernel/proc.c
+++ b/kernel/proc.c
@@ -5,15 +5,19 @@
 #include "spinlock.h"
 #include "proc.h"
 #include "defs.h"
+#include "mem.h"
 
 struct cpu cpus[NCPU];
 
 struct proc proc[NPROC];
+struct mem mem[NPROC]; // will be used for memory synchronization
 
 struct proc *initproc;
 
 int nextpid = 1;
+int nextmemid = 1;
 struct spinlock pid_lock;
+struct spinlock memid_lock;
 
 extern void forkret(void);
 static void freeproc(struct proc *p);
@@ -51,11 +55,18 @@ procinit(void)
   
   initlock(&pid_lock, "nextpid");
   initlock(&wait_lock, "wait_lock");
+  initlock(&memid_lock, "nextmemid");
   for(p = proc; p < &proc[NPROC]; p++) {
       initlock(&p->lock, "proc");
       p->state = UNUSED;
       p->kstack = KSTACK((int) (p - proc));
   }
+  struct mem *m;
+  for (m = mem; m < &mem[NPROC]; m++) {
+    initlock(&m->lock, "mem");
+    m->is_allocated = 0;
+    m->ref_count = 0;
+  }
 }
 
 // Must be called with interrupts disabled,
@@ -102,12 +113,24 @@ allocpid()
   return pid;
 }
 
+int allocmemid()
+{
+  int memid;
+  
+  acquire(&memid_lock);
+  memid = nextmemid;
+  nextmemid = nextmemid + 1;
+  release(&memid_lock);
+
+  return memid;
+}
+
 // Look in the process table for an UNUSED proc.
 // If found, initialize state required to run in the kernel,
 // and return with p->lock held.
 // If there are no free procs, or a memory allocation fails, return 0.
 static struct proc*
-allocproc(void)
+allocproc(int is_thread)
 {
   struct proc *p;
 
@@ -123,6 +146,20 @@ allocproc(void)
 
 found:
   p->pid = allocpid();
+  p->mem_id = allocmemid();
+  if (is_thread) {
+    p->is_thread = 1;
+  }
+  else {
+    for (int i = 0; i < NPROC; i++) {
+      if (mem[i].is_allocated == 0) {
+        mem[i].is_allocated = 1;
+        mem[i].ref_count = 1;
+        p->mem = &mem[i];
+        break;
+      }
+    }
+  }
   p->state = USED;
 
   // Allocate a trapframe page.
@@ -156,10 +193,15 @@ static void
 freeproc(struct proc *p)
 {
   if(p->trapframe)
-    kfree((void*)p->trapframe);
+    kfree((void*)p->trapframe); // do not free trampoline
   p->trapframe = 0;
   if(p->pagetable)
     proc_freepagetable(p->pagetable, p->sz);
+  p->mem->ref_count--;
+  if (p->mem->ref_count == 0) {
+    p->mem->is_allocated = 0;
+    uvmfree(p->pagetable, p->sz);
+  }
   p->pagetable = 0;
   p->sz = 0;
   p->pid = 0;
@@ -212,7 +254,6 @@ proc_freepagetable(pagetable_t pagetable, uint64 sz)
 {
   uvmunmap(pagetable, TRAMPOLINE, 1, 0);
   uvmunmap(pagetable, TRAPFRAME, 1, 0);
-  uvmfree(pagetable, sz);
 }
 
 // a user program that calls exec("/init")
@@ -234,7 +275,7 @@ userinit(void)
 {
   struct proc *p;
 
-  p = allocproc();
+  p = allocproc(0);
   initproc = p;
   
   // allocate one user page and copy initcode's instructions
@@ -261,17 +302,38 @@ growproc(int n)
 {
   uint64 sz;
   struct proc *p = myproc();
-
+  acquire(&p->mem->lock);
   sz = p->sz;
   if(n > 0){
+    // grow p from sz to sz + n
     if((sz = uvmalloc(p->pagetable, sz, sz + n, PTE_W)) == 0) {
+      release(&p->mem->lock);
       return -1;
     }
+    for (struct proc* p2 = proc; p2 < &proc[NPROC]; p2++) {
+      if (p->mem_id == p2->mem_id && p != p2 && p2->state != ZOMBIE) {
+        if (uvmallocmirror(p->pagetable, p2->pagetable, p->sz, p->sz + n) == -1) {
+          goto bad;
+        }
+        p2->sz = sz;
+      }
+    }
   } else if(n < 0){
     sz = uvmdealloc(p->pagetable, sz, sz + n);
+    for (struct proc* p2 = proc; p2 < &proc[NPROC]; p2++) {
+      if (p->mem_id == p2->mem_id && p != p2 && p2->state != ZOMBIE) {
+        uvmdeallocmirror(p2->pagetable, p->sz + n, p->sz);
+      }
+      p2->sz = sz;
+    }
   }
   p->sz = sz;
+  release(&p->mem->lock);
   return 0;
+
+  bad:
+    uvmdealloc(p->pagetable, p->sz + n, p->sz);
+    return -1;
 }
 
 // Create a new process, copying the parent.
@@ -284,7 +346,7 @@ fork(void)
   struct proc *p = myproc();
 
   // Allocate process.
-  if((np = allocproc()) == 0){
+  if((np = allocproc(0)) == 0){
     return -1;
   }
 
@@ -434,6 +496,42 @@ wait(uint64 addr)
   }
 }
 
+int thread_join(uint64 tid) {
+  struct proc *pp;
+  int havekids, pid;
+  struct proc *p = myproc();
+
+  acquire(&wait_lock);
+
+  for(;;){
+    // Scan through table looking for process with tid.
+    for(pp = proc; pp < &proc[NPROC]; pp++){
+      if(pp->parent == p && pp->mem_id == p->mem_id && pp->pid == tid){
+        // make sure the child isn't still in exit() or swtch().
+        acquire(&pp->lock);
+
+        havekids = 1;
+        if(pp->state == ZOMBIE){
+          // Found one.
+          pid = pp->pid;
+          freeproc(pp);
+          release(&pp->lock);
+          release(&wait_lock);
+          return pid;
+        }
+        release(&pp->lock);
+      }
+    }
+
+    if(!havekids || killed(p)){
+      release(&wait_lock);
+      return -1;
+    }
+    
+    sleep(p, &wait_lock);  //DOC: wait-sleep
+  }
+}
+
 // Per-CPU process scheduler.
 // Each CPU calls scheduler() after setting itself up.
 // Scheduler never returns.  It loops, doing:
@@ -681,3 +779,78 @@ procdump(void)
     printf("\n");
   }
 }
+
+int
+thread_create(uint64 fcn, uint64 arg, uint64 stack)
+{
+  int i, pid;
+  struct proc *np;
+  struct proc *p = myproc();
+  uint64 ra = 0xffffffff;
+  uint64 sp = stack + PGSIZE;
+
+  // Allocate process.
+  if((np = allocproc(1)) == 0){
+    return -1;
+  }
+
+  acquire(&p->mem->lock);
+
+  // Copy user memory from parent to child.
+  if(uvmmirror(p->pagetable, np->pagetable, p->sz) < 0){
+    freeproc(np);
+    release(&p->mem->lock);
+    return -1;
+  }
+
+  np->mem_id = p->mem_id;
+  np->mem = p->mem;
+  np->mem->ref_count++;
+  np->sz = p->sz;
+
+  // copy saved user registers.
+  *(np->trapframe) = *(p->trapframe);
+
+  sp -= sizeof(uint64);
+  sp -= sp % 16; // align to 16-byte boundary
+
+  if (copyout(np->pagetable, sp, (char *)(&ra), sizeof(uint64)) < 0) {
+    freeproc(np);
+    release(&p->mem->lock);
+    return -1;
+  }
+
+  np->trapframe->ra = ra;
+  np->trapframe->epc = fcn;
+  np->trapframe->a0 = arg;
+  np->trapframe->sp = sp;
+
+  // increment reference counts on open file descriptors.
+  for(i = 0; i < NOFILE; i++)
+    if(p->ofile[i])
+      np->ofile[i] = filedup(p->ofile[i]);
+  np->cwd = idup(p->cwd);
+
+
+  safestrcpy(np->name, p->name, sizeof(p->name));
+
+  pid = np->pid;
+
+  release(&np->lock);
+
+  acquire(&wait_lock);
+  if (p->is_thread) {
+    np->parent = p->parent;
+  }
+  else {
+    np->parent = p;
+  }
+  release(&wait_lock);
+
+  acquire(&np->lock);
+  np->state = RUNNABLE;
+  release(&np->lock);
+  
+  release(&p->mem->lock);
+  return pid;
+}
diff --git a/kernel/proc.h b/kernel/proc.h
index d021857..c289027 100644
--- a/kernel/proc.h
+++ b/kernel/proc.h
@@ -104,4 +104,8 @@ struct proc {
   struct file *ofile[NOFILE];  // Open files
   struct inode *cwd;           // Current directory
   char name[16];               // Process name (debugging)
+
+  int is_thread;               // if it is thread
+  int mem_id;                  // All threads will have the same physical pages with the mother, hence the same memory ID
+  struct mem *mem;             // pointer to the memory struct
 };
diff --git a/kernel/syscall.c b/kernel/syscall.c
index ed65409..f364377 100644
--- a/kernel/syscall.c
+++ b/kernel/syscall.c
@@ -101,6 +101,10 @@ extern uint64 sys_unlink(void);
 extern uint64 sys_link(void);
 extern uint64 sys_mkdir(void);
 extern uint64 sys_close(void);
+extern uint64 sys_yield(void);
+extern uint64 sys_thread_create(void);
+extern uint64 sys_thread_join(void);
+extern uint64 sys_thread_exit(void);
 
 // An array mapping syscall numbers from syscall.h
 // to the function that handles the system call.
@@ -126,6 +130,10 @@ static uint64 (*syscalls[])(void) = {
 [SYS_link]    sys_link,
 [SYS_mkdir]   sys_mkdir,
 [SYS_close]   sys_close,
+[SYS_yield]   sys_yield,
+[SYS_thread_create] sys_thread_create,
+[SYS_thread_join]   sys_thread_join,
+[SYS_thread_exit]   sys_thread_exit,
 };
 
 void
diff --git a/kernel/syscall.h b/kernel/syscall.h
index bc5f356..205a585 100644
--- a/kernel/syscall.h
+++ b/kernel/syscall.h
@@ -20,3 +20,7 @@
 #define SYS_link   19
 #define SYS_mkdir  20
 #define SYS_close  21
+#define SYS_yield  22
+#define SYS_thread_create 23
+#define SYS_thread_join 24
+#define SYS_thread_exit 25
diff --git a/kernel/sysproc.c b/kernel/sysproc.c
index 1de184e..fd3a2a1 100644
--- a/kernel/sysproc.c
+++ b/kernel/sysproc.c
@@ -89,3 +89,35 @@ sys_uptime(void)
   release(&tickslock);
   return xticks;
 }
+
+uint64
+sys_yield(void)
+{
+  yield();
+  return 0;
+}
+
+uint64
+sys_thread_create(void)
+{
+  uint64 fcn, arg, stack;
+  argaddr(0, &fcn);
+  argaddr(1, &arg);
+  argaddr(2, &stack);
+  return thread_create(fcn, arg, stack);
+}
+
+uint64
+sys_thread_join(void)
+{
+  int tid;
+  argint(0, &tid);
+  return thread_join(tid);
+}
+
+uint64
+sys_thread_exit(void)
+{
+  exit(0);
+  return 0;
+}
\ No newline at end of file
diff --git a/kernel/vm.c b/kernel/vm.c
index 9f69783..4e8c623 100644
--- a/kernel/vm.c
+++ b/kernel/vm.c
@@ -248,6 +248,33 @@ uvmalloc(pagetable_t pagetable, uint64 oldsz, uint64 newsz, int xperm)
   return newsz;
 }
 
+uint64
+uvmallocmirror(pagetable_t old, pagetable_t new, uint64 oldsz, uint64 newsz)
+{
+  pte_t *pte;
+  uint64 pa, i;
+  uint flags;
+
+  // PGROUNDUP rounds a value up to a multiple of PGSIZE
+  oldsz = PGROUNDUP(oldsz);
+  for(i = oldsz; i < newsz; i += PGSIZE){
+    if((pte = walk(old, i, 0)) == 0)
+      panic("uvmcopy: pte should exist");
+    if((*pte & PTE_V) == 0)
+      panic("uvmcopy: page not present");
+    pa = PTE2PA(*pte);
+    flags = PTE_FLAGS(*pte);
+    if(mappages(new, i, PGSIZE, pa, flags) != 0){
+      goto err;
+    }
+  }
+  return 0;
+
+ err:
+  uvmunmap(new, 0, i / PGSIZE, 1);
+  return -1;
+}
+
 // Deallocate user pages to bring the process size from oldsz to
 // newsz.  oldsz and newsz need not be page-aligned, nor does newsz
 // need to be less than oldsz.  oldsz can be larger than the actual
@@ -266,6 +293,20 @@ uvmdealloc(pagetable_t pagetable, uint64 oldsz, uint64 newsz)
   return newsz;
 }
 
+uint64
+uvmdeallocmirror(pagetable_t pagetable, uint64 oldsz, uint64 newsz)
+{
+   if(newsz >= oldsz)
+    return oldsz;
+
+  if(PGROUNDUP(newsz) < PGROUNDUP(oldsz)){
+    int npages = (PGROUNDUP(oldsz) - PGROUNDUP(newsz)) / PGSIZE;
+    uvmunmap(pagetable, PGROUNDUP(newsz), npages, 0); // do not free the physical memory here
+  }
+
+  return newsz;
+}
+
 // Recursively free page-table pages.
 // All leaf mappings must already have been removed.
 void
@@ -319,7 +360,7 @@ uvmcopy(pagetable_t old, pagetable_t new, uint64 sz)
     flags = PTE_FLAGS(*pte);
     if((mem = kalloc()) == 0)
       goto err;
-    memmove(mem, (char*)pa, PGSIZE);
+    memmove(mem, (char*)pa, PGSIZE); // copies PGSIZE amount from pa to mem 
     if(mappages(new, i, PGSIZE, (uint64)mem, flags) != 0){
       kfree(mem);
       goto err;
@@ -332,6 +373,37 @@ uvmcopy(pagetable_t old, pagetable_t new, uint64 sz)
   return -1;
 }
 
+int
+uvmmirror(pagetable_t old, pagetable_t new, uint64 sz)
+{
+  pte_t *pte;
+  uint64 pa, i;
+  uint flags;
+
+  for(i = 0; i < sz; i += PGSIZE){
+    // walk(pagetable, va, alloc) returns the address of the PTE 
+    // in page table pagetable for virtual address va. 
+    // if alloc != 0, walk() creates any required page-table pages.
+    if((pte = walk(old, i, 0)) == 0)
+      panic("uvmcopy: pte should exist");
+    if((*pte & PTE_V) == 0)
+      panic("uvmcopy: page not present");
+    pa = PTE2PA(*pte); // Page Table Entry to Physical Address Translation
+    flags = PTE_FLAGS(*pte);
+    // mappages(pagetable, va, size, pa, perm) creates PTEs for virtual
+    // addresses starting at va referring to physical addresses starting
+    // at pa in pagetable.
+    if(mappages(new, i, PGSIZE, pa, flags) != 0){
+      goto err;
+    }
+  }
+  return 0;
+
+ err:
+  uvmunmap(new, 0, i / PGSIZE, 1);
+  return -1;
+}
+
 // mark a PTE invalid for user access.
 // used by exec for the user stack guard page.
 void
diff --git a/user/thread_mutex.h b/user/thread_mutex.h
new file mode 100644
index 0000000..485047d
--- /dev/null
+++ b/user/thread_mutex.h
@@ -0,0 +1,60 @@
+// Mutual exclusion lock.
+struct thread_mutex {
+  uint locked;       // Is the lock held?
+
+  // For debugging:
+  int proc;           // The process holding lock
+};
+
+void
+thread_mutex_init(struct thread_mutex *lk)
+{
+  lk->locked = 0;
+  lk->proc = 0;
+}
+
+// Acquire the lock.
+// Loops (spins) until the lock is acquired.
+void
+thread_mutex_lock(struct thread_mutex *lk)
+{
+  // On RISC-V, sync_lock_test_and_set turns into an atomic swap:
+  //   a5 = 1
+  //   s1 = &lk->locked
+  //   amoswap.w.aq a5, a5, (s1)
+  while(__sync_lock_test_and_set(&lk->locked, 1) != 0)
+    yield();
+
+  // Tell the C compiler and the processor to not move loads or stores
+  // past this point, to ensure that the critical section's memory
+  // references happen strictly after the lock is acquired.
+  // On RISC-V, this emits a fence instruction.
+  __sync_synchronize();
+
+  // Record info about lock acquisition for holding() and debugging.
+  lk->proc = getpid();
+}
+
+// Release the lock.
+void
+thread_mutex_unlock(struct thread_mutex *lk)
+{
+  lk->proc = 0;
+
+  // Tell the C compiler and the CPU to not move loads or stores
+  // past this point, to ensure that all the stores in the critical
+  // section are visible to other CPUs before the lock is released,
+  // and that loads in the critical section occur strictly before
+  // the lock is released.
+  // On RISC-V, this emits a fence instruction.
+  __sync_synchronize();
+
+  // Release the lock, equivalent to lk->locked = 0.
+  // This code doesn't use a C assignment, since the C standard
+  // implies that an assignment might be implemented with
+  // multiple store instructions.
+  // On RISC-V, sync_lock_release turns into an atomic swap:
+  //   s1 = &lk->locked
+  //   amoswap.w zero, zero, (s1)
+  __sync_lock_release(&lk->locked);
+}
\ No newline at end of file
diff --git a/user/thread_spinlock.h b/user/thread_spinlock.h
new file mode 100644
index 0000000..d4ec899
--- /dev/null
+++ b/user/thread_spinlock.h
@@ -0,0 +1,60 @@
+// Mutual exclusion lock.
+struct thread_spinlock {
+  uint locked;       // Is the lock held?
+
+  // For debugging:
+  int proc;           // The process holding lock
+};
+
+void
+thread_spin_init(struct thread_spinlock *lk)
+{
+  lk->locked = 0;
+  lk->proc = 0;
+}
+
+// Acquire the lock.
+// Loops (spins) until the lock is acquired.
+void
+thread_spin_lock(struct thread_spinlock *lk)
+{
+  // On RISC-V, sync_lock_test_and_set turns into an atomic swap:
+  //   a5 = 1
+  //   s1 = &lk->locked
+  //   amoswap.w.aq a5, a5, (s1)
+  while(__sync_lock_test_and_set(&lk->locked, 1) != 0)
+    ;
+
+  // Tell the C compiler and the processor to not move loads or stores
+  // past this point, to ensure that the critical section's memory
+  // references happen strictly after the lock is acquired.
+  // On RISC-V, this emits a fence instruction.
+  __sync_synchronize();
+
+  // Record info about lock acquisition for holding() and debugging.
+  lk->proc = getpid();
+}
+
+// Release the lock.
+void
+thread_spin_unlock(struct thread_spinlock *lk)
+{
+  lk->proc = 0;
+
+  // Tell the C compiler and the CPU to not move loads or stores
+  // past this point, to ensure that all the stores in the critical
+  // section are visible to other CPUs before the lock is released,
+  // and that loads in the critical section occur strictly before
+  // the lock is released.
+  // On RISC-V, this emits a fence instruction.
+  __sync_synchronize();
+
+  // Release the lock, equivalent to lk->locked = 0.
+  // This code doesn't use a C assignment, since the C standard
+  // implies that an assignment might be implemented with
+  // multiple store instructions.
+  // On RISC-V, sync_lock_release turns into an atomic swap:
+  //   s1 = &lk->locked
+  //   amoswap.w zero, zero, (s1)
+  __sync_lock_release(&lk->locked);
+}
\ No newline at end of file
diff --git a/user/threads.c b/user/threads.c
new file mode 100644
index 0000000..fa52d6d
--- /dev/null
+++ b/user/threads.c
@@ -0,0 +1,80 @@
+#include "kernel/types.h"
+#include "kernel/stat.h"
+#include "user/user.h"
+#include "user/thread_spinlock.h"
+#include "user/thread_mutex.h"
+
+struct balance
+{
+    char name[32];
+    int amount;
+};
+
+volatile int total_balance = 0;
+struct thread_spinlock lock;
+struct thread_mutex mlock;
+
+volatile unsigned int delay(unsigned int d)
+{
+    unsigned int i;
+    for (i = 0; i < d; i++)
+    {
+        __asm volatile("nop" ::
+                           :);
+    }
+
+    return i;
+}
+
+void do_work(void *arg)
+{
+    int i;
+    int old;
+
+    struct balance *b = (struct balance *)arg;
+    printf("Starting do_work: s:%s\n", b->name);
+
+    for (i = 0; i < b->amount; i++)
+    {
+        // lock and mlock will be implemented by you.
+        // thread_spin_lock(&lock);
+        thread_mutex_lock(&mlock);
+        old = total_balance;
+        delay(100000);
+        if (old != total_balance)
+            printf("we will miss an update. old: %d total_balance: %d\n", old, total_balance);
+        total_balance = old + 1;
+        // thread_spin_unlock(&lock);
+        thread_mutex_unlock(&mlock);
+    }
+
+    printf("Done s:%x\n", b->name);
+
+    thread_exit();
+    return;
+}
+
+int main(int argc, char *argv[])
+{
+    thread_spin_init(&lock);
+    thread_mutex_init(&mlock);
+    struct balance b1 = {"b1", 3200};
+    struct balance b2 = {"b2", 2800};
+
+    void *s1, *s2;
+    int thread1, thread2, r1, r2;
+
+    s1 = malloc(4096); // 4096 is the PGSIZE defined in kernel/riscv.h
+    s2 = malloc(4096);
+
+    thread1 = thread_create(do_work, (void *)&b1, s1);
+    thread2 = thread_create(do_work, (void *)&b2, s2);
+
+    r1 = thread_join(thread1);
+    r2 = thread_join(thread2);
+
+    printf("Threads finished: (%d):%d, (%d):%d, shared balance:%d\n",
+           thread1, r1, thread2, r2, total_balance);
+
+    return 0;
+}
\ No newline at end of file
diff --git a/user/user.h b/user/user.h
index 4d398d5..a78186a 100644
--- a/user/user.h
+++ b/user/user.h
@@ -22,6 +22,10 @@ int getpid(void);
 char* sbrk(int);
 int sleep(int);
 int uptime(void);
+int yield(void);
+int thread_create(void(*fcn)(void*), void *arg, void*stack);
+int thread_join(int);
+int thread_exit(void);
 
 // ulib.c
 int stat(const char*, struct stat*);
diff --git a/user/usys.pl b/user/usys.pl
index 01e426e..dbce72c 100755
--- a/user/usys.pl
+++ b/user/usys.pl
@@ -36,3 +36,7 @@ entry("getpid");
 entry("sbrk");
 entry("sleep");
 entry("uptime");
+entry("yield");
+entry("thread_create");
+entry("thread_join");
+entry("thread_exit");
\ No newline at end of file
